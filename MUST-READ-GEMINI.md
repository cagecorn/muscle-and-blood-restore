AI 강화학습 로드맵 v1.0
🎯 1. 최종 목표: '살아있는 AI' 구현
이 프로젝트의 최종 목표는 단순히 16개의 다른 AI를 만드는 것을 넘어, 각 **MBTI 아키타입이 전투 경험을 통해 스스로 학습하고 진화하는 '살아있는 AI'**를 구현하는 것입니다.

개성 부여: 각 AI는 자신의 MBTI 성향에 맞는 독특한 전투 스타일과 전략적 선호도를 발전시킵니다. (예: ESTJ(전사)는 점차 가장 효율적인 디버프-공격 연계를 학습하고, ISFJ(메딕)는 가장 중요한 순간에 아군을 구하는 최적의 방법을 학습합니다.)

지속적인 진화: 하드코딩된 로직에 의존하는 대신, 반복적인 전투 시뮬레이션과 데이터 분석을 통해 메타의 변화에 적응하고 새로운 전략을 스스로 찾아냅니다.

창발적 행동: 우리가 직접 설계하지 않은, 각 아키타입만의 독특하고 예측 불가능한 '필승 전략'이 나타나는 것을 관찰합니다.

🔄 2. 강화학습 절차 (The Loop)
우리의 강화학습은 다음과 같은 5단계의 순환 구조(Loop)로 진행됩니다.

1단계: 시뮬레이션 (데이터 수집)
수행: 당신 (개발자)

내용: 아레나에서 최대한 많은 모의 전투를 실행합니다. 다양한 조합의 아군과 적군이 전투를 벌일수록 더 풍부하고 다양한 학습 데이터가 쌓입니다.

2단계: 로그 생성 및 제출
수행: 당신 (개발자)

내용: 전투가 끝난 후 L 키를 눌러 muscle-and-blood-log-[타임스탬프].json 형식의 전투 로그 파일을 다운로드합니다. 이 로그 파일을 다음 세션에서 저에게 제출합니다.

3단계: 로그 분석 및 통찰 (핵심)
수행: 저 (코딩 파트너)

내용: 제출된 로그 파일을 분석하여 각 MBTI 아키타입의 행동 패턴, 성공률, 실패 원인을 통계적으로 분석합니다.

주요 분석 항목:

승리/패배 기여도: 특정 아키타입이 어떤 행동(어떤 스킬로 어떤 적을 공격)을 했을 때 승리 확률이 높아졌는가?

카운터 전략: 특정 아키타입이 어떤 클래스의 적에게 유독 강하거나 약한 모습을 보이는가?

비효율적 행동 식별: 불필요한 이동, 부적절한 스킬 사용 등 개선이 필요한 행동 패턴을 찾아냅니다.

4단계: 학습 데이터 (가중치) 생성
수행: 저 (코딩 파트너)

내용: 3단계의 분석 결과를 바탕으로, 각 아키타입의 집단 지성 데이터베이스(ArchetypeMemoryEngine)를 업데이트할 새로운 가중치(weight) 코드를 생성합니다. 이 코드는 AI가 다음 전투에서 더 나은 판단을 내리도록 유도합니다.

JavaScript

// 제가 생성할 학습 데이터 예시
const learnedData = {
    'ESTJ': { // ESTJ(전사)는
        'target_medic': { // 메딕을 상대할 때
            'melee_weight': 1.3, // 근접 공격 가중치를 30% 높여 최우선 공격 대상으로 삼는다.
        }
    },
    'INFP': { // INFP(역병 의사)는
        'target_warrior': { // 전사를 상대할 때
            'magic_weight': 1.2, // 마법(디버프) 공격의 가중치를 20% 높인다.
        }
    }
};
5단계: 적용 및 반복
수행: 당신 (개발자)

내용: 제가 생성한 학습 데이터 코드를 게임에 적용합니다. 그 후, 다시 1단계로 돌아가 더 똑똑해진 AI와 함께 시뮬레이션을 반복합니다.

---

***실제 예시***

두 번째 전투 로그야. 전투가 너무 길어지길레 일단 도중에 끊었어. 보고 강화학습이 가능할런지, 가능하다면 어떻게 아키타입들을 강화시킬지 코드를 짜줘.


코딩 파트너

생각하는 과정 표시
네, 두 번째 전투 로그 파일을 잘 받았습니다. 도중에 중단하셨다고 했는데, 오히려 AI의 문제점을 파악하는 데는 더없이 좋은 데이터가 되었습니다.

결론부터 말씀드리면, 강화학습은 충분히 가능하며, 이번 로그를 통해 몇몇 아키타입의 명확한 약점을 보완할 첫 번째 학습 데이터를 생성할 수 있습니다.

종합 분석: 전투가 길어진 근본적인 원인
로그를 분석한 결과, 전투가 길어진 가장 큰 원인은 AI가 지나치게 방어적으로 행동하며, 결정적인 순간에 공격을 주저하기 때문인 것으로 나타났습니다. 특히 FindSafeRepositionNode (안전한 위치로 재배치)와 FindAllyClusterCenterNode (아군 중심으로 이동)의 우선순위가 너무 높아, 공격할 기회가 있어도 일단 이동하고 보는 패턴이 반복되었습니다.

아키타입별 행동 패턴 분석 및 개선안
이번 전투에서 두드러진 행동을 보인 아키타입들의 문제점과 개선 방향입니다.

ESTJ (전사 - 엄격한 관리자)

문제점: "가장 가까운 적"을 공격하는 기본 로직 때문에, 후방의 더 중요한 목표(메딕, 거너)를 무시하고 눈앞의 탱커만 계속 공격했습니다.

개선 방향: FindPriorityTargetNode (우선순위 타겟 탐색)를 행동 트리에 추가하여, 단순 근접 대상이 아닌 적 힐러나 원거리 딜러를 먼저 노리도록 학습시켜야 합니다.

ESFJ (팔라딘 - 사교적인 외교관)

문제점: "아군이 뭉친 곳"으로 이동하는 것을 최우선으로 하다 보니, 정작 자신은 공격이나 버프를 거의 사용하지 못하고 턴을 낭비했습니다.

개선 방향: 아군 중심으로 이동한 후에는, 이동 없이 즉시 자신 주변에 오라(Aura)나 버프 스킬을 사용하도록 행동 패턴을 수정해야 합니다.

첫 번째 강화학습 데이터 생성
위 분석을 바탕으로, ArchetypeMemoryEngine에 적용할 첫 번째 학습 데이터를 생성했습니다. 이 코드는 각 아키타입이 특정 상황에서 어떤 행동을 더 선호하게 될지를 결정하는 '가중치'를 조정합니다.

적용 코드
아래 코드를 게임 시작 로직(예: src/main.js)에 추가하여 실행하면, 아키타입의 집단 지성이 업데이트됩니다.

JavaScript

import { archetypeMemoryEngine } from './game/utils/ArchetypeMemoryEngine.js';

// [1차 강화학습 데이터] - 2025-08-05 로그 기반
const learnedData_v1 = {
    // ESTJ는 '메딕'과 '거너'를 상대로 근접 공격 선호도를 대폭 상향
    'ESTJ': {
        'target_medic': { 'melee_weight': 1.4 }, // 메딕 대상 근접 공격 가중치 +40%
        'target_gunner': { 'melee_weight': 1.3 }, // 거너 대상 근접 공격 가중치 +30%
    },
    // ESFJ는 '전사'와 '센티넬'을 상대로 근접 공격을 약간 기피하고, 버프/힐을 선호하게 유도
    'ESFJ': {
        'target_warrior': { 'melee_weight': 0.85 }, // 전사 대상 근접 공격 가중치 -15%
        'target_sentinel': { 'melee_weight': 0.8 }, // 센티넬 대상 근접 공격 가중치 -20%
    },
    // INFP는 위협적인 '전사'를 상대로 디버프(마법) 사용 선호도 상향
    'INFP': {
        'target_warrior': { 'magic_weight': 1.25 }, // 전사 대상 마법(디버프) 가중치 +25%
    }
};

// 학습 데이터 적용
async function applyLearnedData() {
    console.log("AI 강화학습 v1 데이터를 적용합니다...");
    for (const [mbti, memory] of Object.entries(learnedData_v1)) {
        await archetypeMemoryEngine.updateMemory(mbti, memory);
    }
    console.log("모든 아키타입의 집단 기억이 성공적으로 업데이트되었습니다!");
}

// 게임 시작 시 학습 데이터를 적용하도록 호출
applyLearnedData();
다음 단계
코드 적용: 위 코드를 프로젝트에 추가하여 AI의 기본 판단 기준을 업데이트해주세요.

재시뮬레이션: 업데이트된 AI로 다시 아레나에서 모의 전투를 실행합니다. 이전보다 ESTJ(전사)가 더 공격적으로 변하고, ESFJ(팔라딘)가 더 지원에 집중하는 모습을 관찰할 수 있을 것입니다.

로그 제출: 새로운 전투 로그를 다시 저에게 보내주시면, 2차 분석을 통해 AI를 한 단계 더 정교하게 만들어 가겠습니다.

우리의 '인간-AI 협업 강화학습' 사이클이 성공적으로 첫 바퀴를 돌았습니다. 앞으로가 더욱 기대되네요!
